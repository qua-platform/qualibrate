{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p>Welcome to the QUAlibrate documentation! QUAlibrate is an advanced, open-source calibration platform designed to streamline the calibration process for quantum computers. Specifically built for quantum processing units (QPUs) with OPX controllers, QUAlibrate provides tools that empower users\u2014from researchers to engineers\u2014to efficiently tune up their quantum systems with precision and flexibility.</p>"},{"location":"#what-is-qualibrate","title":"What is QUAlibrate?","text":"<p>QUAlibrate is a comprehensive platform that enables users to create, manage, and execute calibration routines for quantum computers. It allows researchers to think in terms of their quantum system, without needing to delve into hardware-specific complexities. By offering a modular, adaptable approach to calibration, QUAlibrate scales easily from single-qubit calibrations to complex, multi-qubit workflows.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Calibration Nodes: Reusable calibration scripts transformed into <code>QualibrationNode</code> instances that can be executed independently or as part of a larger workflow.</li> <li>Calibration Graphs: Directed acyclic graphs (<code>QualibrationGraph</code>) that link multiple calibration nodes to form adaptive calibration routines based on prior results, with advanced features like looping, failure handling, and nested subgraphs.</li> <li>Web Interface: A user-friendly web app that enables you to execute calibration nodes and graphs with live updates and visualization, simplifying your workflow.</li> <li>Scalable System: Designed for scalability, QUAlibrate can handle both small- and large-scale QPU systems, allowing for seamless integration with multiple qubits and complex calibration tasks.</li> <li>Quantum Abstract Machine (QUAM): A digital representation of your quantum system, ensuring reproducibility and transparency in your calibration processes.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Installation: Begin by installing QUAlibrate using <code>pip</code>. Detailed instructions are available on the Installation page.</li> <li>Configuration: Set up the system by running the configuration command and modifying the configuration file as needed. Refer to the Configuration guide for more details.</li> <li>Run Calibrations: Start running calibration nodes or graphs through either the Python interface or the web app. Learn more about each method in the Calibration Nodes and Calibration Graphs sections.</li> <li>Use the Web App: Access and operate your calibration routines through an easy-to-use web interface. More information is available on the Web App page.</li> </ol>"},{"location":"#core-components","title":"Core Components","text":""},{"location":"#calibration-nodes","title":"Calibration Nodes","text":"<p>Calibration nodes (<code>QualibrationNode</code>) are the fundamental building blocks of the QUAlibrate system. They represent specific calibration tasks, such as adjusting the qubit frequency or optimizing gate pulses. Nodes are modular and reusable, making them highly adaptable for different types of quantum systems and calibration goals.</p>"},{"location":"#calibration-library","title":"Calibration Library","text":"<p>The Calibration Library is a repository of all calibration nodes and graphs, organized for ease of use and accessibility. It allows researchers to manage, update, and execute calibration routines in a streamlined way, ensuring consistency across different experiments and hardware configurations.</p>"},{"location":"#calibration-graphs","title":"Calibration Graphs","text":"<p>Calibration graphs (<code>QualibrationGraph</code>) combine multiple calibration nodes into a directed acyclic graph (DAG) to represent complete calibration routines. Each graph represents a workflow that adapts based on the results of previous nodes, creating an efficient and automated calibration process.</p> <p>For advanced features like looping, failure handling, and nested subgraphs, see Advanced Calibration Graphs.</p>"},{"location":"#web-app","title":"Web App","text":"<p>QUAlibrate's web interface allows users to run calibration nodes and graphs intuitively. With live updates, parameter adjustments, and graphical results, the web app makes calibration processes more accessible to users without deep programming expertise.</p>"},{"location":"#release-notes","title":"Release Notes","text":"<p>QUAlibrate is updated regularly to provide new features, performance improvements and bug fixes. These release notes provide more information about those changes. </p>"},{"location":"#community-and-support","title":"Community and Support","text":"<p>QUAlibrate is fully open source, and contributions are welcome! If you want to report a bug, request a new feature, or contribute code, check out our GitHub repository. For questions, feel free to open an issue or reach out through the community.</p>"},{"location":"#license","title":"License","text":"<p>QUAlibrate is licensed under the BSD-3 license. For more details, refer to the LICENSE file.</p>"},{"location":"advanced_calibration_graphs/","title":"Advanced Calibration Graphs","text":""},{"location":"advanced_calibration_graphs/#introduction","title":"Introduction","text":"<p>QUAlibrate's advanced calibration graph features enable sophisticated calibration workflows through a modern context manager API, adaptive looping, failure handling, and hierarchical graph composition. These features build upon the basic calibration graphs functionality and provide powerful tools for creating robust, complex calibration routines.</p> <p>This guide assumes you have access to the demo calibration nodes (01-07) that are automatically installed with QUAlibrate as part of the demo project.</p>"},{"location":"advanced_calibration_graphs/#the-context-manager-api","title":"The Context Manager API","text":"<p>The recommended way to create calibration graphs is using the <code>QualibrationGraph.build()</code> context manager. This API provides a clean, intuitive syntax for graph construction and ensures proper graph finalization.</p>"},{"location":"advanced_calibration_graphs/#basic-usage","title":"Basic Usage","text":"<pre><code>from qualibrate import QualibrationGraph, QualibrationLibrary, GraphParameters\n\nlibrary = QualibrationLibrary.get_active_library()\n\nclass TuneupParameters(GraphParameters):\n    qubits: list[str] = [\"q1\"]\n\n# Build the graph using the context manager\nwith QualibrationGraph.build(\"my_tuneup_graph\", parameters=TuneupParameters()) as graph:\n    # Get nodes from the library (automatically copied)\n    rabi_node = library.nodes[\"02_demo_rabi\"]\n    graph.add_node(rabi_node)\n\n    ramsey_node = library.nodes[\"05_demo_ramsey\"]\n    graph.add_node(ramsey_node)\n\n    graph.connect(rabi_node, ramsey_node)\n\n# Graph is now finalized and ready to run\nif __name__ == \"__main__\":\n    result = graph.run(qubits=[\"q1\", \"q2\"])\n</code></pre>"},{"location":"advanced_calibration_graphs/#how-it-works","title":"How It Works","text":"<p>The context manager handles the graph lifecycle automatically:</p> <ol> <li>Building Phase: When you enter the <code>with</code> block, the graph is in building mode. You can add nodes, create connections, and configure loops.</li> <li>Finalization: When exiting the <code>with</code> block, the graph is automatically finalized. This validates the graph structure, ensures all nodes are properly copied from the library, and builds the internal execution graph.</li> <li>Execution: After the context manager exits, the graph is ready to run.</li> </ol>"},{"location":"advanced_calibration_graphs/#graph-composition-and-nested-subgraphs","title":"Graph Composition and Nested Subgraphs","text":"<p>Complex calibration workflows can be organized hierarchically by nesting graphs within graphs. A <code>QualibrationGraph</code> can be added as a node in another graph, creating a parent-child relationship.</p>"},{"location":"advanced_calibration_graphs/#creating-nested-subgraphs","title":"Creating Nested Subgraphs","text":"<pre><code>from qualibrate import QualibrationGraph, QualibrationLibrary, GraphParameters\n\nlibrary = QualibrationLibrary.get_active_library()\n\nclass TuneupParameters(GraphParameters):\n    qubits: list[str] = [\"q1\"]\n\n# Build the main graph\nwith QualibrationGraph.build(\"full_calibration\", parameters=TuneupParameters()) as graph:\n    # Add an initial node\n    rabi_node = library.nodes[\"02_demo_rabi\"]\n    graph.add_node(rabi_node)\n\n    # Create a nested subgraph for coherence measurements\n    with QualibrationGraph.build(\"coherence_characterization\", parameters=TuneupParameters()) as subgraph:\n        # Add nodes to the subgraph\n        ramsey_node = library.nodes[\"05_demo_ramsey\"]\n        subgraph.add_node(ramsey_node)\n\n        t1_node = library.nodes[\"06_demo_t1\"]\n        subgraph.add_node(t1_node)\n\n        # Connect nodes within the subgraph\n        subgraph.connect(ramsey_node, t1_node)\n\n    # Add the subgraph as a node in the main graph\n    graph.add_node(subgraph)\n\n    # Connect the initial node to the subgraph\n    graph.connect(rabi_node, subgraph)\n\n    # Add a final node\n    rb_node = library.nodes[\"07_demo_randomized_benchmarking\"]\n    graph.add_node(rb_node)\n    graph.connect(subgraph, rb_node)\n</code></pre>"},{"location":"advanced_calibration_graphs/#benefits-of-nested-subgraphs","title":"Benefits of Nested Subgraphs","text":"<ul> <li>Logical organization: Group related calibration steps together</li> <li>Reusability: Create subgraphs that can be used in multiple parent graphs</li> <li>Clarity: Break complex workflows into manageable, understandable pieces</li> <li>Atomic execution: The subgraph executes as a single unit from the parent graph's perspective</li> </ul>"},{"location":"advanced_calibration_graphs/#looping-and-adaptive-calibration","title":"Looping and Adaptive Calibration","text":"<p>Looping allows a calibration node to be executed multiple times, enabling retry logic and adaptive calibration strategies. QUAlibrate supports both simple iteration limits and sophisticated conditional loops.</p>"},{"location":"advanced_calibration_graphs/#simple-retry-loops","title":"Simple Retry Loops","text":"<p>Use <code>max_iterations</code> to retry a node a fixed number of times:</p> <pre><code>with QualibrationGraph.build(\n    \"tuneup_with_retries\",\n    parameters=TuneupParameters(),\n) as graph:\n    rabi_node = library.nodes[\"02_demo_rabi\"]\n    graph.add_node(rabi_node)\n\n    # Retry the node up to 3 times\n    graph.loop(rabi_node, max_iterations=3)\n\n    # Continue with the rest of the graph\n    ramsey_node = library.nodes[\"05_demo_ramsey\"]\n    graph.add_node(ramsey_node)\n    graph.connect(rabi_node, ramsey_node)\n</code></pre> <p>The node will execute exactly <code>max_iterations</code> times, regardless of success or failure outcomes</p>"},{"location":"advanced_calibration_graphs/#conditional-loops","title":"Conditional Loops","text":"<p>For adaptive calibration, you can provide a condition function that determines whether to continue iterating based on the calibration results:</p> <pre><code>from qualibrate import QualibrationNode\n\ndef should_repeat_ramsey(node: QualibrationNode, target: str) -&gt; bool:\n    \"\"\"Retry until T2* crosses the target threshold.\"\"\"\n    fit = node.results.get(\"fit_results\", {}).get(target, {})\n    t2_star = fit.get(\"t2_star\")\n\n    # Retry if fit failed or T2* is below target\n    if not fit.get(\"success\") or t2_star is None:\n        return True\n\n    t2_us = t2_star / 1e-6\n    target_us = graph.parameters.target_t2_star_us\n    if t2_us &lt; target_us:\n        return True\n\n    return False  # Target met, stop looping\n\nwith QualibrationGraph.build(\n    \"adaptive_ramsey\",\n    parameters=AdaptiveRamseyParameters(),\n) as graph:\n    ramsey_node = library.nodes[\"05_demo_ramsey\"]\n    graph.add_node(ramsey_node)\n\n    # Set up adaptive loop with condition function\n    graph.loop(\n        ramsey_node,\n        on=should_repeat_ramsey,\n        max_iterations=5,\n    )\n</code></pre>"},{"location":"advanced_calibration_graphs/#condition-function-signature","title":"Condition Function Signature","text":"<p>Condition functions must accept two parameters:</p> <ul> <li><code>node: QualibrationNode</code> - The node instance, allowing access to <code>node.results</code></li> <li><code>target: str</code> - The specific target (e.g., qubit) being evaluated</li> </ul> <p>The function should return:</p> <ul> <li><code>True</code> if the target should be calibrated again in another iteration</li> <li><code>False</code> if calibration for this target is complete</li> </ul> <p>Per-Target Looping</p> <p>Condition functions are called separately for each target. This enables per-target adaptive logic where some qubits may continue iterating while others are finished.</p>"},{"location":"advanced_calibration_graphs/#combining-conditions-and-max-iterations","title":"Combining Conditions and Max Iterations","text":"<p>When both a condition function and <code>max_iterations</code> are specified, the loop continues while:</p> <ul> <li>The condition function returns <code>True</code> for any target, AND</li> <li>The iteration count has not reached <code>max_iterations</code></li> </ul> <p>This provides a safety bound on adaptive algorithms while still allowing sophisticated logic.</p>"},{"location":"advanced_calibration_graphs/#failure-handling","title":"Failure Handling","text":"<p>Real-world calibration workflows must account for failures. QUAlibrate provides <code>connect_on_failure()</code> to define explicit failure paths in your calibration graph.</p>"},{"location":"advanced_calibration_graphs/#basic-failure-handling","title":"Basic Failure Handling","text":"<pre><code>with QualibrationGraph.build(\n    \"tuneup_with_failure_handling\",\n    parameters=TuneupParameters(),\n) as graph:\n    # Primary calibration path\n    rabi_node = library.nodes[\"02_demo_rabi\"]\n    graph.add_node(rabi_node)\n    graph.loop(rabi_node, max_iterations=3)\n\n    # Success path: continue with refined Rabi\n    refined_rabi_node = library.nodes[\"04_demo_rabi_refined\"]\n    graph.add_node(refined_rabi_node)\n    graph.connect(rabi_node, refined_rabi_node)\n\n    # Failure path: run diagnostic node\n    failure_handler_node = library.nodes[\"06_demo_t1\"]\n    failure_handler_node.name = \"failure_diagnostics\"\n    graph.add_node(failure_handler_node)\n\n    # If rabi_node fails after all retries, go to failure handler\n    graph.connect_on_failure(rabi_node, failure_handler_node)\n</code></pre>"},{"location":"advanced_calibration_graphs/#how-failure-handling-works","title":"How Failure Handling Works","text":"<p>When a node completes execution:</p> <ul> <li>Success outcome: Targets that succeeded follow edges created with <code>connect()</code></li> <li>Failure outcome: Targets that failed follow edges created with <code>connect_on_failure()</code></li> </ul> <p>This allows you to:</p> <ul> <li>Define recovery procedures for failed calibrations</li> <li>Route failed targets to diagnostic nodes</li> <li>Implement fallback calibration strategies</li> <li>Ensure the graph continues executing even when some calibrations fail</li> </ul>"},{"location":"advanced_calibration_graphs/#combining-loops-and-failure-handling","title":"Combining Loops and Failure Handling","text":"<p>Failure edges are only followed after a node completes all its loop iterations:</p> <pre><code>with QualibrationGraph.build(\"robust_calibration\", parameters=params) as graph:\n    risky_node = library.nodes[\"01_demo_qubit_spectroscopy\"]\n    graph.add_node(risky_node)\n\n    # Try up to 3 times\n    graph.loop(risky_node, max_iterations=3)\n\n    # Success path\n    next_node = library.nodes[\"02_demo_rabi\"]\n    graph.add_node(next_node)\n    graph.connect(risky_node, next_node)\n\n    # Failure path (only after exhausting retries)\n    recovery_node = library.nodes[\"06_demo_t1\"]\n    graph.add_node(recovery_node)\n    graph.connect_on_failure(risky_node, recovery_node)\n</code></pre> <p>In this example, <code>risky_node</code> will retry up to 3 times. Only if it fails after all retries will targets be routed to <code>recovery_node</code>.</p>"},{"location":"advanced_calibration_graphs/#complete-example-full-qubit-characterization","title":"Complete Example: Full Qubit Characterization","text":"<p>Here's a comprehensive example that combines all advanced features:</p> <pre><code>from qualibrate import GraphParameters, QualibrationGraph, QualibrationLibrary\n\nlibrary = QualibrationLibrary.get_active_library()\n\nclass FullCharacterizationParameters(GraphParameters):\n    qubits: list[str] = [\"q1\"]\n\nwith QualibrationGraph.build(\n    \"full_qubit_characterization\",\n    parameters=FullCharacterizationParameters(),\n) as graph:\n    # 1. Initial spectroscopy\n    spectroscopy_node = library.nodes[\"01_demo_qubit_spectroscopy\"]\n    graph.add_node(spectroscopy_node)\n\n    # 2. Gate optimization subgraph with retries\n    with QualibrationGraph.build(\n        \"gate_optimization\",\n        parameters=FullCharacterizationParameters(),\n    ) as gate_subgraph:\n        rabi_node = library.nodes[\"02_demo_rabi\"]\n        gate_subgraph.add_node(rabi_node)\n        gate_subgraph.loop(rabi_node, max_iterations=2)\n\n        refined_rabi_node = library.nodes[\"04_demo_rabi_refined\"]\n        gate_subgraph.add_node(refined_rabi_node)\n        gate_subgraph.connect(rabi_node, refined_rabi_node)\n\n    graph.add_node(gate_subgraph)\n    graph.connect(spectroscopy_node, gate_subgraph)\n\n    # 3. Coherence characterization subgraph (parallel T1 and Ramsey)\n    with QualibrationGraph.build(\n        \"coherence_characterization\",\n        parameters=FullCharacterizationParameters(),\n    ) as coherence_subgraph:\n        t1_node = library.nodes[\"06_demo_t1\"]\n        ramsey_node = library.nodes[\"05_demo_ramsey\"]\n        coherence_subgraph.add_node(t1_node)\n        coherence_subgraph.add_node(ramsey_node)\n        # No connection: run in parallel\n\n    graph.add_node(coherence_subgraph)\n    graph.connect(gate_subgraph, coherence_subgraph)\n\n    # 4. Final gate fidelity assessment\n    rb_node = library.nodes[\"07_demo_randomized_benchmarking\"]\n    graph.add_node(rb_node)\n    graph.connect(coherence_subgraph, rb_node)\n\n    # 5. Failure handling for gate optimization\n    graph.connect_on_failure(gate_subgraph, rb_node)\n\nif __name__ == \"__main__\":\n    result = graph.run()\n    print(f\"Characterization complete: {result}\")\n</code></pre> <p>This example demonstrates:</p> <ul> <li>Context manager usage for clean graph construction</li> <li>Nested subgraphs for logical organization (gate optimization, coherence characterization)</li> <li>Looping with retries on the Rabi node</li> <li>Failure handling that routes gate optimization failures directly to final assessment</li> <li>Parallel execution of T1 and Ramsey (no connection between them)</li> </ul>"},{"location":"advanced_calibration_graphs/#migration-from-legacy-api","title":"Migration from Legacy API","text":"<p>If you have existing graphs created without the context manager, migrating is straightforward:</p>"},{"location":"advanced_calibration_graphs/#before-legacy-api","title":"Before (Legacy API)","text":"<pre><code>from qualibrate import QualibrationLibrary, QualibrationGraph, GraphParameters\nfrom qualibrate.orchestration.basic_orchestrator import BasicOrchestrator\n\nlibrary = QualibrationLibrary.get_active_library()\n\nclass Parameters(GraphParameters):\n    qubits: list[str] = None\n\ngraph = QualibrationGraph(\n    name=\"workflow1\",\n    parameters=Parameters(),\n    nodes={\n        \"qubit_spec\": library.nodes[\"qubit_spec\"],\n        \"rabi\": library.nodes[\"rabi\"],\n        \"ramsey\": library.nodes[\"ramsey\"],\n    },\n    connectivity=[(\"qubit_spec\", \"rabi\"), (\"rabi\", \"ramsey\")],\n    orchestrator=BasicOrchestrator(skip_failed=True),\n)\n</code></pre>"},{"location":"advanced_calibration_graphs/#after-context-manager-api","title":"After (Context Manager API)","text":"<pre><code>from qualibrate import QualibrationLibrary, QualibrationGraph, GraphParameters\n\nlibrary = QualibrationLibrary.get_active_library()\n\nclass Parameters(GraphParameters):\n    qubits: list[str] = None\n\nwith QualibrationGraph.build(\n    \"workflow1\",\n    parameters=Parameters(),\n) as graph:\n    qubit_spec = library.nodes[\"qubit_spec\"]\n    rabi = library.nodes[\"rabi\"]\n    ramsey = library.nodes[\"ramsey\"]\n\n    graph.add_node(qubit_spec)\n    graph.add_node(rabi)\n    graph.add_node(ramsey)\n\n    graph.connect(qubit_spec, rabi)\n    graph.connect(rabi, ramsey)\n</code></pre> <p>The context manager API is more explicit, easier to read, and provides better error messages when graph construction fails.</p>"},{"location":"calibration_graphs/","title":"Calibration Graphs","text":""},{"location":"calibration_graphs/#introduction","title":"Introduction","text":"<p>Tuning up a qubit or multiple qubits in a quantum processing unit (QPU) involves executing a sequence of calibration nodes. The next calibration node to be executed may depend on the measurement outcome of one or more previous nodes, allowing for adaptive decision-making based on previous results, which is crucial for efficient calibration. This process is called a calibration routine and can be represented using a directed acyclic graph (DAG) together with an orchestrator.</p> <p>In QUAlibrate, a <code>QualibrationGraph</code> is used to represent these calibration routines. The nodes in the DAG are <code>QualibrationNode</code> instances, and the edges between nodes determine the execution order: a destination node can only be executed once its origin node has successfully completed.</p> <p>Advanced Features</p> <p>This guide covers the basics of creating and running calibration graphs. For advanced features including looping, failure handling, and nested subgraphs, see Advanced Calibration Graphs.</p>"},{"location":"calibration_graphs/#graph-execution-using-targets-and-an-orchestrator","title":"Graph Execution Using Targets and an Orchestrator","text":"<p>To execute a calibration graph, two key elements are required: the <code>targets</code> and the orchestrator. Targets specify what is being calibrated, while the orchestrator manages the execution sequence.</p> <p>The <code>targets</code> specify the entities to which the graph should be applied, typically qubits. These targets allow the calibration nodes to understand which parts of the quantum system they should act upon.</p> <p>The orchestrator, specifically a <code>QualibrationOrchestrator</code>, determines the sequence of node execution in the graph. It traverses the <code>QualibrationGraph</code>, deciding which <code>QualibrationNode</code> should be executed next based on the outcomes of previous nodes. The orchestrator ensures that nodes are executed in the correct order and selects which targets (e.g., qubits) should be used for each node.</p> <p>Due to the dependencies between nodes, orchestrating their execution can be complex. The complexity arises from the need to account for varying outcomes and ensure that all dependencies are satisfied. As a result, there is no single optimal <code>QualibrationOrchestrator</code>. Different types of orchestrators can be used, each focusing on specific properties such as simplicity, reliability, or efficiency.</p>"},{"location":"calibration_graphs/#qualibrationnode-requirements","title":"<code>QualibrationNode</code> Requirements","text":"<p>To be used within a <code>QualibrationGraph</code>, a <code>QualibrationNode</code> must meet certain requirements.</p>"},{"location":"calibration_graphs/#specifying-node-targets-qubits","title":"Specifying Node Targets (Qubits)","text":"<p>The first requirement is to specify the targets for the node. By default, these targets are <code>qubits</code>, meaning that <code>qubits</code> should be defined as one of the parameters for the node:</p> <pre><code>from typing import Optional, List\nfrom qualibrate import NodeParameters\n\nclass Parameters(NodeParameters):\n    qubits: Optional[List[str]] = None\n    # Include other parameters here\n</code></pre> <p>This setup indicates that the <code>QualibrationNode</code> can receive a list of qubits as targets for calibration.</p> Using <code>targets</code> other than <code>qubits</code> <p>By default, the <code>targets</code> parameter is set to <code>qubits</code>, as this is the most common use case for calibrations. However, the <code>targets</code> can be modified to accommodate different types by changing the class variable <code>Parameters.targets_name</code>. For example, if the node performs calibration on qubit pairs rather than individual qubits, it can be specified as follows:</p> <pre><code>from typing import ClassVar, Optional, List\n\nclass Parameters(NodeParameters):\n    targets_name: ClassVar[str] = \"qubit_pairs\"\n    qubit_pairs: Optional[List[str]] = None\n    # Include other parameters here\n</code></pre> <p>Targets Type</p> <p>Currently, each target is expected to be of type <code>str</code>. Therefore, the <code>targets</code> parameter type should be <code>Optional[List[str]]</code> with a default value of <code>None</code>. In the future, support for additional types will be added.</p>"},{"location":"calibration_graphs/#adding-node-outcome-per-target","title":"Adding Node Outcome per Target","text":"<p>A <code>QualibrationNode</code> must also indicate the calibration outcome for each target. This is essential for deciding the subsequent calibration steps based on success or failure. This is important for determining subsequent steps based on which targets were calibrated successfully and which ones failed. For instance, if the node was executed with the parameter <code>qubits = [\"q0\", \"q1\"]</code>, then the outcomes can be set as follows:</p> <pre><code>node.outcomes = {\n    \"q0\": \"successful\",\n    \"q1\": \"failed\",\n}\n</code></pre> <p>The <code>outcomes</code> attribute is crucial for guiding the next steps in the calibration process. If no outcome is provided, the <code>QualibrationOrchestrator</code> assumes that the node was successful for all targets.</p>"},{"location":"calibration_graphs/#creating-a-qualibrationgraph","title":"Creating a QualibrationGraph","text":"<p>Similar to a <code>QualibrationNode</code>, a <code>QualibrationGraph</code> should be defined in a dedicated Python script and saved in the <code>qualibrate_runner.calibration_library_folder</code> path specified in the configuration file.</p>"},{"location":"calibration_graphs/#example-creating-a-qualibrationgraph","title":"Example: Creating a <code>QualibrationGraph</code>","text":"<p>In this example, we will create a graph composed of three <code>QualibrationNode</code>s: qubit spectroscopy \u2192 Rabi \u2192 Ramsey. The arrow indicates that each subsequent node can only be executed if the previous node had a successful outcome for that target.</p> <p>Demo Calibration Nodes</p> <p>This example uses demo calibration nodes that are automatically installed with QUAlibrate in the project <code>\"demo_project\"</code>. These nodes (<code>01_demo_qubit_spectroscopy</code>, <code>02_demo_rabi</code>, <code>05_demo_ramsey</code>) are available in the calibration library and can be used for testing and learning purposes.</p>"},{"location":"calibration_graphs/#importing-qualibrate","title":"Importing <code>qualibrate</code>","text":"<p>The first step is to import the relevant classes from <code>qualibrate</code>:</p> <pre><code>from typing import List, Optional\nfrom qualibrate import QualibrationLibrary, QualibrationGraph, GraphParameters\n</code></pre>"},{"location":"calibration_graphs/#loading-the-calibration-library","title":"Loading the Calibration Library","text":"<p>The next step is to load the calibration library:</p> <pre><code>library = QualibrationLibrary.get_active_library()\n</code></pre> <p>This will scan the library folder and load all existing nodes and graphs, which allows us to use the nodes in the graph.</p>"},{"location":"calibration_graphs/#defining-graph-input-parameters","title":"Defining Graph Input Parameters","text":"<p>Next, define the graph parameters. Typically, this only consists of the graph targets, which are <code>qubits</code> by default:</p> <pre><code>class Parameters(GraphParameters):\n    qubits: Optional[List[str]] = None\n</code></pre>"},{"location":"calibration_graphs/#constructing-the-qualibrationgraph","title":"Constructing the <code>QualibrationGraph</code>","text":"<p>Now we are ready to create the <code>QualibrationGraph</code> using the context manager API:</p> <pre><code>with QualibrationGraph.build(\n    \"workflow1\",\n    parameters=Parameters(),\n) as graph:\n    # Get nodes from the library (automatically copied)\n    qubit_spec = library.nodes[\"01_demo_qubit_spectroscopy\"]\n    rabi = library.nodes[\"02_demo_rabi\"]\n    ramsey = library.nodes[\"05_demo_ramsey\"]\n\n    # Add nodes to the graph\n    graph.add_node(qubit_spec)\n    graph.add_node(rabi)\n    graph.add_node(ramsey)\n\n    # Connect nodes to define execution order\n    graph.connect(qubit_spec, rabi)\n    graph.connect(rabi, ramsey)\n</code></pre> <p>Here is an explanation of each part:</p> <ul> <li><code>QualibrationGraph.build()</code>: Creates a graph in building mode using a context manager</li> <li><code>name</code>: Unique name for the <code>QualibrationGraph</code>, used by the <code>QualibrationLibrary</code> to index the graph</li> <li><code>parameters</code>: An instance of the previously defined <code>Parameters</code> class</li> <li><code>library.nodes[\"...\"]</code>: Retrieves nodes from the library (automatically creating copies)</li> <li><code>graph.add_node()</code>: Adds a node to the graph</li> <li><code>graph.connect()</code>: Defines edges between nodes, where the destination node executes after the source node succeeds</li> </ul> <p>When the <code>with</code> block exits, the graph is automatically finalized and validated.</p>"},{"location":"calibration_graphs/#running-the-qualibrationgraph","title":"Running the QualibrationGraph","text":"<p>After creating the graph, it can be executed as follows:</p> <pre><code>graph.run(qubits=[\"q1\", \"q2\", \"q3\"])\n</code></pre>"},{"location":"calibration_graphs/#full-qualibrationgraph-file","title":"Full <code>QualibrationGraph</code> File","text":"<p>Combining all the elements from the previous sections, the final script containing the <code>QualibrationGraph</code> looks like this:</p> <pre><code>from typing import List, Optional\nfrom qualibrate import QualibrationLibrary, QualibrationGraph, GraphParameters\n\nlibrary = QualibrationLibrary.get_active_library()\n\n# Define graph target parameters\nclass Parameters(GraphParameters):\n    qubits: Optional[List[str]] = None\n\n# Create the QualibrationGraph using the context manager\nwith QualibrationGraph.build(\n    \"workflow1\",  # Unique graph name\n    parameters=Parameters(),  # Instantiate graph parameters\n) as graph:\n    # Get demo nodes from the library (automatically copied)\n    qubit_spec = library.nodes[\"01_demo_qubit_spectroscopy\"]\n    rabi = library.nodes[\"02_demo_rabi\"]\n    ramsey = library.nodes[\"05_demo_ramsey\"]\n\n    # Add nodes to the graph\n    graph.add_node(qubit_spec)\n    graph.add_node(rabi)\n    graph.add_node(ramsey)\n\n    # Connect nodes to define execution order\n    graph.connect(qubit_spec, rabi)\n    graph.connect(rabi, ramsey)\n\n# Run the calibration graph for qubits q1, q2, and q3\nif __name__ == \"__main__\":\n    graph.run(qubits=[\"q1\", \"q2\", \"q3\"])\n</code></pre> <p>This script can be executed from any IDE or terminal. Additionally, it can also be run from the QUAlibrate Web App, provided it is saved in the <code>qualibrate_runner.calibration_library_folder</code> path specified in the configuration file.</p>"},{"location":"calibration_graphs/#qualibrationorchestrator","title":"QualibrationOrchestrator","text":"<p>The <code>QualibrationOrchestrator</code> is responsible for running a <code>QualibrationGraph</code>, i.e. deciding which <code>QualibrationNode</code> to execute next and what <code>targets</code> (e.g. qubits) should be calibrated in that node. This decision process typically relies on the node outcomes of executed nodes. The choices that a <code>QualibrationOrchestrator</code> makes include</p> <ul> <li>What should happen to a target if its calibration failed in a node? Should it be dropped from further calibrations, or should the failed calibration be remedied, for example by attempting the same or a previous calibration again?</li> <li>If multiple calibration nodes can be executed next, which one has priority?</li> <li>Should the next <code>QualibrationNode</code> run on multiple targets simultaneously, or on one at a time?</li> </ul> <p>There is no single right answer to this question, and therefore different subclasses of <code>QualibrationOrchestrator</code> are created that implement different graph traversal algorithm. Currently, QUAlibrate has the <code>BasicOrchestrator</code> that implements a straightforward graph traversal. Additional orchestrators will be added to QUAlibrate in the future, and users can also implement custom graph traversal algorithms by subclassing the <code>QualibrationOrchestrator</code>.</p>"},{"location":"calibration_graphs/#basicorchestrator","title":"BasicOrchestrator","text":"<p>The <code>BasicOrchestrator</code> is a straightforward graph traversal algorithm with a single parameter <code>skip_failed</code>, which determines whether to continue calibrating failed targets. The functionality of this algorithm is described here.</p> <ol> <li>For each target, collect all nodes that have not yet been executed and whose predecessors have been executed.</li> <li>Run each of these nodes, grouping targets together that are executed on the same node.    If a node outcome <code>failed</code> for a target, then the action depends on <code>skip_failed</code>:    a. <code>skip_failed = True</code> \u2192 Remove the target from any further calibrations    b. <code>skip_failed = False</code> \u2192 ignore the node outcome and keep using the target for further calibration.</li> <li>Repeat 1 and 2 until the list of nodes in Step 1 is empty.</li> </ol> <p>The <code>BasicOrchestrator</code> can be instantiated as follows:</p> <pre><code>from qualibrate.orchestration.basic_orchestrator import BasicOrchestrator\n\norchestrator = BasicOrchestrator(skip_failed=True)\n</code></pre>"},{"location":"calibration_library/","title":"Calibration Library","text":""},{"location":"calibration_library/#overview","title":"Overview","text":"<p>The Calibration Library in QUAlibrate serves as a central location for storing and organizing calibration nodes and graphs. This library allows users to easily manage, update, and execute various calibration routines, providing a streamlined process for configuring quantum systems. Calibration nodes in the library are modular components that can be included as part of a calibration graph or executed externally, for example, through the QUAlibrate Web App.</p>"},{"location":"calibration_library/#loading-the-calibration-library","title":"Loading the Calibration Library","text":"<p>The library of calibration nodes and graphs can be loaded in Python using the following code snippet:</p> <pre><code>from qualibrate import QualibrationLibrary\n\nlibrary = QualibrationLibrary.get_active_library()\n</code></pre> <p>This will use the folder path specified by <code>qualibrate_runner.calibration_library_folder</code> if it is defined in the configuration file. Alternatively, a custom folder can be specified using the keyword argument <code>library_folder</code>:</p> <pre><code>library = QualibrationLibrary(library_folder=\"/path/to/custom/folder\")\n</code></pre>"},{"location":"calibration_library/#example-loading-and-running-a-calibration-node","title":"Example: Loading and Running a Calibration Node","text":"<p>Consider a calibration script called <code>res_spec.py</code> located in the <code>library_folder</code>. The contents of this script include the following `QualibrationNode`:</p> <pre><code>from qualibrate import NodeParameters, QualibrationNode\n\nclass Parameters(NodeParameters):\n    f_center: float = 5e9\n    f_span: float = 50e6\n\nnode = QualibrationNode(\"resonator_spectroscopy\", parameters=Parameters())\n</code></pre> <p>In this example, the node <code>resonator_spectroscopy</code> can be accessed from the calibration library as follows:</p> <pre><code>res_spec_node = library.nodes[\"resonator_spectroscopy\"]\n</code></pre> <p>To execute this node, use the <code>run</code> method:</p> <pre><code>res_spec_node.run(f_center=5e9, f_span=100e6)\n</code></pre> <p>Note that the keyword arguments correspond to those defined in the <code>Parameters</code> class. These arguments are optional, as the parameters have default values. This allows the default parameters to be overridden when the node is run through the library.</p>"},{"location":"calibration_library/#loading-and-running-a-calibration-graph","title":"Loading and running a calibration graph","text":"<p>Similar to calibration nodes, a calibration graph can also be defined in the library folder.\u00a0A graph with name \"single_qubit_tuneup\"\u00a0can be accessed using</p> <pre><code>single_qubit_graph = library.graphs[\"single_qubit_tuneup\"]\n</code></pre> <p>and can then be executed through</p> <pre><code>single_qubit_graph.run(qubits=[\"q0\", \"q1\"])\n</code></pre> <p>where qubits\u00a0would be a list of qubits that the graph should calibrate.</p>"},{"location":"calibration_library/#integration-with-the-qualibrate-web-app","title":"Integration with the QUAlibrate Web App","text":"<p>The Calibration Library is also integrated with the QUAlibrate Web App. The web app scans the library folder for available nodes and graphs, allowing users to execute them through an intuitive graphical interface. Users can modify parameters as needed before running a node or graph, providing flexibility and ease of use.</p>"},{"location":"calibration_library/#best-practices","title":"Best Practices","text":"<p>To get the most out of the Calibration Library, consider the following best practices:</p> <ul> <li>Organize by Functionality: Group nodes by their purpose, such as qubit tune-up, gate calibration, or diagnostics, to make it easier to locate and execute specific calibration routines.</li> <li>Consistent Parameter Naming: Use consistent naming conventions for parameters to facilitate easy modification and compatibility across different nodes.</li> <li>Document Each Node: Ensure that each calibration node is well-documented, including its purpose, parameters, and expected outcomes, to help other users understand and use the node effectively.</li> </ul>"},{"location":"calibration_nodes/","title":"Calibration Nodes","text":""},{"location":"calibration_nodes/#introduction","title":"Introduction","text":"<p>Calibration nodes in QUAlibrate encapsulate calibration routines into reusable components that can run independently or as part of larger workflows. This guide demonstrates how to transform an existing calibration script into a <code>QualibrationNode</code> to fully leverage the flexibility and scalability of QUAlibrate.</p>"},{"location":"calibration_nodes/#initial-script","title":"Initial Script","text":"<p>As a basic example, let us assume we already have a calibration script. Such a script typically runs a program on quantum control hardware. For this example, we will use a simplified script that emulates data for demonstration purposes, rather than an actual quantum control script:</p> <pre><code>import numpy as np\nfrom matplotlib import pyplot as plt\n\n# Define input parameters\nspan = 20e3\nnum_points = 101\n\n# Generate data\noffset = np.random.rand() * span / 5\nwidth = span / 20\nnoise_factor = 0.2\nsweep_values = np.linspace(-span / 2, span / 2, num_points)\ngaussian = np.exp(-((sweep_values + offset) / width) ** 2)\nnoise = noise_factor * np.random.rand(num_points)\ndata = gaussian + noise\n\n# Analyse results\npeak_idx = np.argmax(data)\npeak_coord = sweep_values[peak_idx]\npeak_val = data[peak_idx]\n\n# Plot results\nfig = plt.figure()\nplt.plot(sweep_values, data)\nplt.plot(peak_coord, peak_val, \"*\", ms=14)\n</code></pre> <p>The emulated data consists of a peak with noise superimposed, and the script extracts the peak. The resulting figure should look something like the following </p>"},{"location":"calibration_nodes/#conversion-into-a-qualibrationnode","title":"Conversion into a <code>QualibrationNode</code>","text":"<p>We now make adjustments to the previous script to transform the code into a QualibrationNode. We first present the individual modifications, and then present the fully converted node.</p>"},{"location":"calibration_nodes/#importing-qualibrate","title":"Importing <code>qualibrate</code>","text":"<p>The first step is to import the relevant classes from <code>qualibrate</code>. We need <code>NodeParameters</code> to encapsulate the parameters and <code>QualibrationNode</code> to create the node:</p> <pre><code>from qualibrate import NodeParameters, QualibrationNode\n</code></pre>"},{"location":"calibration_nodes/#defining-input-parameters","title":"Defining Input Parameters","text":"<p>Instead of defining parameters as standalone variables, we group them together in a <code>NodeParameters</code> subclass:</p> <pre><code>class Parameters(NodeParameters):\n    span: float = 20e3\n    num_points: int = 101\n</code></pre> <p>Using <code>NodeParameters</code> allows parameters to be modified externally, such as through the QUAlibrate web interface. For example, this makes it easy to adapt calibration settings for different hardware configurations without changing the code.</p>"},{"location":"calibration_nodes/#creating-the-qualibrationnode","title":"Creating the <code>QualibrationNode</code>","text":"<p>Next, we instantiate the <code>QualibrationNode</code> with a unique name (<code>\"emulated_calibration\"</code>) and provide an instance of the <code>Parameters</code> class:</p> <pre><code>node = QualibrationNode(\"emulated_calibration\", parameters=Parameters())\n</code></pre> <p>This will enable the <code>QualibrationLibrary</code> to run this calibration node externally, provided that the script is located in the <code>calibration_library_folder</code> of the configuration file.</p> <p>Avoid significant code before this point</p> <p>The <code>QualibrationLibrary</code> executes each calibration node script sequentially until a <code>QualibrationNode</code> is instantiated. This approach optimizes efficiency by stopping further execution once the node is created, preventing unnecessary code execution and saving system resources. Avoid placing time-consuming operations, such as hardware initialization, before this point to ensure efficient scanning by the library.</p>"},{"location":"calibration_nodes/#using-node-parameters-in-the-script","title":"Using Node Parameters in the Script","text":"<p>The original script can now be adapted to use parameters from the <code>NodeParameters</code> instance:</p> <pre><code>sweep_values = np.linspace(-node.parameters.span / 2, node.parameters.span / 2, node.parameters.num_points)\n</code></pre> <p>This ensures that parameters can be easily adjusted when the node is called externally.</p>"},{"location":"calibration_nodes/#registering-results","title":"Registering Results","text":"<p>Once the data has been retrieved and analysed, we register the results with the node to ensure they are saved after execution:</p> <pre><code>node.results = {\n    \"figure\": fig,\n    \"arrays\": {\"sweep_values\": sweep_values, \"data\": data},\n    \"peak_coord\": peak_coord,\n    \"peak_val\": peak_val,\n}\n</code></pre> <p>A variety of results can be stored, including</p> <ul> <li>Standard types: <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, etc.</li> <li>Nested lists and dictionaries</li> <li>Numpy arrays</li> <li>Xarray datasets</li> <li>Matplotlib figures</li> </ul> <p>Additional result types can be supported via plugins.</p>"},{"location":"calibration_nodes/#saving-results","title":"Saving Results","text":"<p>Finally, the registered results are saved using the following command:</p> <pre><code>node.save()\n</code></pre> <p>This saves the results in the location specified by <code>qualibrate.storage.location</code> in the configuration file.</p>"},{"location":"calibration_nodes/#fully-converted-node","title":"Fully Converted Node","text":"<p>After following all the steps, the fully converted node looks as follows:</p> <pre><code>import numpy as np\nfrom matplotlib import pyplot as plt\nfrom qualibrate import NodeParameters, QualibrationNode\n\n# Define input parameters for QualibrationNode\nclass Parameters(NodeParameters):\n    span: float = 20e3\n    num_points: int = 101\n\n# Create QualibrationNode\nnode = QualibrationNode(\"emulated_calibration\", parameters=Parameters())\n\n# Generate data using node parameters\noffset = np.random.rand() * node.parameters.span / 5\nwidth = node.parameters.span / 20\nnoise_factor = 0.2\nsweep_values = np.linspace(\n    -node.parameters.span / 2,\n    node.parameters.span / 2,\n    node.parameters.num_points\n)\ngaussian = np.exp(-((sweep_values + offset) / width) ** 2)\nnoise = noise_factor * np.random.rand(node.parameters.num_points)\ndata = gaussian + noise\n\n# Analyse results\npeak_idx = np.argmax(data)\npeak_coord = sweep_values[peak_idx]\npeak_val = data[peak_idx]\n\n# Plot results\nfig = plt.figure()\nplt.plot(sweep_values, data)\nplt.plot(peak_coord, peak_val, \"*\", ms=14)\n\n# Register results\nnode.results = {\n    \"figure\": fig,\n    \"arrays\": {\"sweep_values\": sweep_values, \"data\": data},\n    \"peak_coord\": peak_coord,\n    \"peak_val\": peak_val,\n}\n\n# Save results\nnode.save()\n</code></pre> <p>This node can still be executed directly from any code editor and shouldn't cause any different behaviour. The advantage is that it can now also be called externally, for example as part of a calibration graph, or through the QUAlibrate Web App.</p>"},{"location":"calibration_nodes/#combining-quam-with-qualibrate","title":"Combining QUAM with QUAlibrate","text":"<p>QUAM (Quantum Abstract Machine) abstracts the QUA programming language, letting researchers focus on qubits and quantum operations instead of hardware. Integrated with QUAlibrate, QUAM streamlines calibration, enabling smooth transitions between quantum programming and system calibration.</p> <p>QUAM serves as a persistent digital model of the quantum setup. Calibration nodes update specific entries in QUAM, creating an evolving system model. Each calibration node loads the latest version of QUAM, ensuring consistency and efficiency throughout the calibration process.</p> <p>For details on QUAM please visit http://qua-platform.github.io/quam/.</p> <p>To incorporate QUAM into the <code>QualibrationNode</code>, we assume QUAM can be loaded using a method like <code>QuAM.load()</code>. It can then be added to the node as follows:</p> <pre><code>node.machine = QuAM.load()\n</code></pre> <p>This step automatically includes a snapshot of QUAM when saving the node using <code>node.save()</code>.</p> <p>Additionally, if <code>quam.state_path</code> is set in the configuration file, it will be updated when saving the node.</p> <p>Finally, the <code>QualibrationNode</code> also provides a way to record any changes to QUAM interactively by encapsulating these state updates as follows:</p> <pre><code>with node.record_state_updates():\n    # Modify the resonance frequency of a qubit\n    machine.qubits[\"q0\"].f_01 = 5.1e9\n</code></pre> <p>This will simply update the values if the script is executed normally. However, if the node is executed through the QUAlibrate Web App, any changes will be presented as a proposed state update to the user, allowing them to interactively accept or decline the changes based on the measurement outcomes.</p> <p>Note that this action should be performed before calling <code>node.save()</code>.</p>"},{"location":"calibration_nodes/#structuring-nodes-with-actions-optional","title":"Structuring Nodes with Actions (Optional)","text":"<p>While the examples above show the entire logic within a single script, you can optionally structure your <code>QualibrationNode</code> code using Node Actions. This approach involves breaking down the node's logic into distinct functions marked with the <code>@node.run_action</code> decorator.</p> <p>Using Node Actions offers several advantages:</p> <ul> <li>Improved Readability &amp; Maintainability: Encapsulating logic (e.g., data generation, analysis, saving) into named functions makes the script easier to understand and modify.</li> <li>Clearer Execution Flow: Conditional execution (<code>skip_if</code>) can be handled cleanly within the decorator, avoiding complex <code>if/else</code> blocks in the main script body.</li> <li>Enhanced Modularity: Actions function as largely independent units, sharing data explicitly via <code>node.namespace</code>. This reduces coupling between different parts of the script.</li> <li>Interactivity: Actions can often be recognized as runnable cells in editors like VS Code, simplifying debugging and interactive execution of specific steps.</li> <li>Web App Integration: The QUAlibrate Web App displays the currently running Node Action, providing better visibility into the execution progress of your calibration script.</li> </ul> <p>For a detailed explanation and examples of how to use Node Actions, including data sharing and conditional execution, please refer to the Node Actions page.</p>"},{"location":"configuration/","title":"Configuration File","text":""},{"location":"configuration/#config-file-location","title":"Config File Location","text":"<p>The QUAlibrate configuration file is a TOML file that contains all the settings for the QUAlibrate software. It is located at <code>~/.qualibrate/config.toml</code>.</p> <p>It can be generated using the command</p> <pre><code>qualibrate config\n</code></pre>"},{"location":"configuration/#command-line-options","title":"Command Line Options","text":"<p>This is a list of all the command line options available for the <code>qualibrate config</code> command. These arguments can also be found by calling <code>qualibrate config --help</code></p>"},{"location":"configuration/#-config-path","title":"<code>--config-path</code>","text":"<p>Path to the configuration file. If the path points to a file, it will be read and the old configuration will be reused, except for the variables specified by the user. If the file does not exist, a new one will be created. If the path points to a directory, a check will be made to see if files with the default name exist. The default file names are:</p> <ol> <li><code>qualibrate.toml</code> - a project-specific configuration file</li> <li><code>config.toml</code> - a general qualibrate configuration file    If a project-specific configuration file exists, it will be used.</li> </ol> <p>If a project-specific configuration file does not exist, a general configuration file will be checked. If both files are not found in the directory, a general configuration file will be created in the directory.</p> <p>Default: <code>~/.qualibrate/config.toml</code></p>"},{"location":"configuration/#-auto-accept","title":"<code>--auto-accept</code>","text":"<p>Flag responsible for whether to skip confirmation of the generated config.</p> <p>If the flag is specified in the invoked command, the configuration will be written to the file without confirmation by the user. If the flag is not used, the user will be shown the generated config based on: 1) the old config file, if it existed; 2) default values; 3) values entered by the user. Confirmation will also be requested whether the file was generated correctly.</p>"},{"location":"configuration/#-password","title":"<code>--password</code>","text":"<p>Password used to authorize users.</p> <p>By default, no password is used. Everyone has access to the API. If a password is specified during configuration, you must log in to access the API.</p> <p>Default: <code>None</code> Config entry: <code>qualibrate_composite.password</code></p>"},{"location":"configuration/#-spawn-runner","title":"<code>--spawn-runner</code>","text":"<p>This flag indicates whether the <code>qualibrate-runner</code> service should be started. This service is designed to run nodes and graphs. The service can be spawned independently.</p> <p>Default: <code>True</code> Config entry: <code>qualibrate_composite.runner.spawn</code></p>"},{"location":"configuration/#-runner-address","title":"<code>--runner-address</code>","text":"<p>Address of <code>qualibrate-runner</code> service. If the service is spawned by the <code>qualibrate</code> then the default address should be kept as is. If you are running the service separately, you must specify its address.</p> <p>Default: <code>http://localhost:8001/execution</code> Config entry: <code>qualibrate_composite.runner.address</code></p>"},{"location":"configuration/#-runner-timeout","title":"<code>--runner-timeout</code>","text":"<p>Maximum waiting time for a response from the <code>qualibrate-runner</code> service.</p> <p>Default: <code>1.0</code> Config entry: <code>qualibrate_composite.runner.timeout</code></p>"},{"location":"configuration/#-runner-calibration-library-resolver","title":"<code>--runner-calibration-library-resolver</code>","text":"<p>String contains python path to the class that represents qualibration library.</p> <p>Default: <code>\"qualibrate.QualibrationLibrary\"</code> Config entry: <code>qualibrate_runner.calibration_library_resolver</code></p>"},{"location":"configuration/#-runner-calibration-library-folder","title":"<code>--runner-calibration-library-folder</code>","text":"<p>Path to the folder contains calibration nodes and graphs.</p> <p>Default: <code>~/.qualibrate/calibrations</code> Config entry: <code>qualibrate_runner.calibration_library_folder</code></p>"},{"location":"configuration/#-spawn-app","title":"<code>--spawn-app</code>","text":"<p>This flag indicates whether the <code>qualibrate-app</code> service should be started. This service is designed to getting info about snapshots. The service can be spawned independently.</p> <p>Default: <code>True</code> Config entry: <code>qualibrate_composite.app.spawn</code></p>"},{"location":"configuration/#-app-static-site-files","title":"<code>--app-static-site-files</code>","text":"<p>Path to the frontend build static files.</p> <p>Default: <code>&lt;env_libs_path&gt;/qualibrate_static</code> Config entry: <code>qualibrate_app.static_site_files</code></p>"},{"location":"configuration/#-storage-type","title":"<code>--storage-type</code>","text":"<p>Type of storage. Only <code>local_storage</code> is supported now. Use specified local path as the database.</p> <p>Default: \"local_storage\" Config entry: <code>qualibrate.storage.type</code></p>"},{"location":"configuration/#-storage-location","title":"<code>--storage-location</code>","text":"<p>Path to the local user storage. Used for storing nodes output data. <code>${...}</code> - config reference.</p> <p>Default: <code>~/.qualibrate/user_storage/${#/qualibrate/project}</code> Config entry: <code>qualibrate.storage.location</code></p>"},{"location":"configuration/#-project","title":"<code>--project</code>","text":"<p>The name of qualibrate app project that will be used for storing runs results and resolving them.</p> <p>Default: <code>\"init_project\"</code> Config entry: <code>qualibrate.project</code></p>"},{"location":"configuration/#-quam-state-path","title":"<code>--quam-state-path</code>","text":"<p>The path to the directory where the active machine state should be stored. </p> <p>Default: <code>None</code> Config entry: <code>quam.state_path</code></p>"},{"location":"configuration/#-log-folder","title":"<code>--log-folder</code>","text":"<p>The path to the directory where the logs should be stored to.</p> <p>Default: <code>QUALIBRATE_PATH / \"logs\"</code> Config entry: <code>qualibrate.log_folder</code></p>"},{"location":"configuration/#environment-variable-override","title":"Environment Variable Override","text":"<p>You can override the default configuration file path by setting the <code>QUALIBRATE_CONFIG_FILE</code> environment variable. This is useful when you want to use multiple configurations or keep your config in a non-standard location.</p>"},{"location":"configuration/#usage","title":"Usage","text":"<p>Set the <code>QUALIBRATE_CONFIG_FILE</code> environment variable to the path of your config file:</p> <p>Linux/macOS - Bash/Zsh: <pre><code>export QUALIBRATE_CONFIG_FILE=/path/to/your/config.toml\nqualibrate config\n</code></pre></p> <p>Windows - Command Prompt (cmd.exe): <pre><code>set QUALIBRATE_CONFIG_FILE=C:\\path\\to\\your\\config.toml\nqualibrate config\n</code></pre></p> <p>To set this permanently, use: <pre><code>setx QUALIBRATE_CONFIG_FILE C:\\path\\to\\your\\config.toml\n</code></pre></p> <p>Windows - PowerShell: <pre><code>$env:QUALIBRATE_CONFIG_FILE = \"C:\\path\\to\\your\\config.toml\"\nqualibrate config\n</code></pre></p> <p>To set this permanently in PowerShell, use: <pre><code>[Environment]::SetEnvironmentVariable(\"QUALIBRATE_CONFIG_FILE\", \"C:\\path\\to\\your\\config.toml\", \"User\")\n</code></pre></p>"},{"location":"configuration/#priority","title":"Priority","text":"<p>When loading the configuration: 1. If <code>QUALIBRATE_CONFIG_FILE</code> environment variable is set, it is used 2. Otherwise, the default location <code>~/.qualibrate/config.toml</code> is used</p> <p>The environment variable takes precedence over the default path.</p>"},{"location":"configuration/#use-cases","title":"Use Cases","text":"<ul> <li>Multiple configurations: Maintain separate configs for different projects or environments</li> <li>Custom locations: Store config files in a custom directory outside <code>~/.qualibrate</code></li> <li>Docker/CI environments: Set the path dynamically in containerized or automated setups</li> <li>Team workflows: Share a common config location for team members</li> </ul>"},{"location":"installation/","title":"Installation Guide","text":"<p>This guide will provide a detailed walkthrough for installing QUAlibrate, a user-programmed calibration software for large-scale quantum computers. This guide will help you set up QUAlibrate, configure it properly, and verify your installation to ensure everything is working smoothly.</p>"},{"location":"installation/#pre-requisites","title":"Pre-requisites","text":"For WindowsFor MacOSFor Linux <ul> <li>Windows 10 (build 1809 and later), or Windows 11</li> <li>3.9 \u2264 Python \u2264 3.11, we recommend Python 3.10 or 3.11</li> </ul> Using a virtual environment in Windows <p>type: tip</p> <p>It is recommended to install QuAM in a Python virtual environment.</p> <p>If using Anaconda, this can be done via</p> <pre><code>conda create -n {environment_name}\nconda activate {environment_name}\n</code></pre> <p>Be sure to replace <code>{environment_name}</code> with a name of your choosing</p> <p>To create a virtual environment without Anaconda, open PowerShell , navigate to a folder where you would like to create a virtual environment, and execute the following command:</p> <pre><code>python -m venv {environment_name}\nsource {environment_name}\\Scripts\\Activate.ps1\n</code></pre> <ul> <li>Tested on MacOS Ventura and MacOS Sonoma</li> <li>3.9 \u2264 Python \u2264 3.11, we recommend Python 3.10 or 3.11</li> </ul> Using a virtual environment in MacOS <p>type: tip</p> <p>It is recommended to install QuAM in a Python virtual environment. To create a virtual environment, open terminal , navigate to a folder where you would like to create a virtual environment, and execute the following command:</p> <pre><code>python -m venv {environment_name}\nsource {environment_name}/bin/activate\n</code></pre> <ul> <li>QuAM has not been tested on Linux. However, it should follow similar instructions as MacOS.</li> </ul>"},{"location":"installation/#install-qualibrate","title":"Install QUAlibrate","text":"<p>To install QUAlibrate, simply run the following command:</p> <pre><code>pip install qualibrate\n</code></pre> <p>This command will fetch the latest stable version of QUAlibrate from PyPI and install it on your machine.</p> <p>This step will also install the following essential QUAlibrate components:</p> <ul> <li>qualibrate-core: Contains all the features needed to create and run calibration nodes and graphs.</li> <li>qualibrate-app: Provides a Web App from which calibrations can be run through a graphical user interface (GUI).</li> <li>qualibrate-runner: A local server that can execute calibration jobs from the QUAlibrate Web App.</li> </ul>"},{"location":"installation/#run-the-configuration-setup","title":"Run the Configuration Setup","text":"<p>After installing QUAlibrate, you need to create a configuration file.\u00a0The configuration file contains important settings, such as default paths and connection details, that can be edited later if needed.</p> <p>Run the following command to start the config generation:</p> <pre><code>qualibrate config\n</code></pre> <p>This will propose a default configuration file located at <code>~/.qualibrate/config.toml</code>.\u00a0You can hit <code>Y</code> to accept the default options.</p> <p>Typically the following two settings need to be configured:</p> <ul> <li><code>qualibrate.storage.location</code>\u00a0specifies the data storage folder</li> <li><code>qualibrate_runner.calibration_library_folder</code>\u00a0\u00a0specifies the folder containing the calibration nodes and graphs.</li> </ul> <p>These settings can either be modified by directly editing the configuration file (<code>~/.qualibrate/config.toml</code>) or through the command line:</p> <pre><code>qualibrate config --storage-location DATA_LOCATION --runner-calibration-library-folder LIBRARY_FOLDER\n</code></pre> <p>where <code>DATA_LOCATION</code>\u00a0and <code>LIBRARY_FOLDER</code>\u00a0need to be modified accordingly.</p>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>To verify that QUAlibrate is installed correctly, you can start the QUAlibrate web interface:</p> <pre><code>qualibrate start\n</code></pre> <ul> <li>If everything is set up properly, the web interface will be accessible at http://localhost:8001.</li> <li>Once started, navigate to this URL in your web browser to confirm that QUAlibrate is running and ready to use.</li> <li>The list of calibrations should be empty as the calibration nodes or graphs still need to be defined.</li> </ul>"},{"location":"installation/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":"<ol> <li> <p>Pip Not Found: If you encounter an error saying <code>pip: command not found</code>, ensure that Python and pip are installed and correctly added to your system's PATH.</p> </li> <li> <p>Permission Errors: If you receive a permission error during installation, try using <code>pip install qualibrate --user</code> to install QUAlibrate for your user account only.</p> </li> <li> <p>Configuration Problems: If there are issues during the configuration setup, manually inspect the configuration file at <code>~/.qualibrate/config.toml</code> to ensure all values are correct.</p> </li> </ol>"},{"location":"installation/#updating-qualibrate","title":"Updating QUAlibrate","text":"<p>To update QUAlibrate to the latest version, you can use the following command:</p> <pre><code>pip install --upgrade qualibrate\n</code></pre> <p>This ensures you always have the latest features and bug fixes.</p>"},{"location":"node_actions/","title":"Node Actions","text":""},{"location":"node_actions/#introduction","title":"Introduction","text":"<p>Node Actions provide a structured way to organize the code within a <code>QualibrationNode</code> while preserving the interactivity essential for calibration tasks. Traditionally, calibration scripts might be long, monolithic files or broken into functions without a standardized execution flow. Node Actions introduce a lightweight mechanism using decorators to define distinct, executable steps within a node script.</p> <p>This approach aims to balance the need for clear, maintainable code structure with the flexibility required for debugging and iterative development common in quantum calibration workflows. It addresses the challenge that overly rigid structures can hinder the quick experimentation needed when tuning quantum systems.</p>"},{"location":"node_actions/#structuring-nodes-with-actions","title":"Structuring Nodes with Actions","text":"<p>The core of this feature is the <code>@node.run_action</code> decorator. By applying this decorator to a function within a <code>QualibrationNode</code> script, you designate that function as a \"Node Action.\"</p> <pre><code>from qualibrate import QualibrationNode, NodeParameters\nfrom typing import Optional # Added for Optional type hint\n\n# Define Parameters (assuming Parameters class exists)\nclass Parameters(NodeParameters):\n    # ... node parameters\n    simulate: bool = False\n    load_data_id: Optional[int] = None\n\n# Instantiate the node\nnode = QualibrationNode(\n    name=\"example_node\",\n    parameters=Parameters()\n)\n# Node setup might occur here, e.g., loading configurations or machine state if needed\n\n# Define an action\n@node.run_action\ndef save_results(node: QualibrationNode):\n    \"\"\"Saves the node's results.\"\"\"\n    print(\"Saving results...\")\n    # Add logic to gather results if needed before saving\n    node.save()\n    print(\"Results saved.\")\n\n# &gt;&gt; Output when script is run:\n# Saving results...\n# Results saved.\n</code></pre> <p>When the Python script containing the node is executed (either directly, via the Calibration Library, or the Web App), functions decorated with <code>@node.run_action</code> are:</p> <ol> <li>Executed Immediately: The function runs as soon as it's defined in     the script flow.</li> <li>Registered: The action is registered with the node instance, making it     potentially available for more advanced control flows or debugging tools     in the future (like re-running specific steps).</li> </ol>"},{"location":"node_actions/#sharing-data-between-actions","title":"Sharing Data Between Actions","text":"<p>Since actions are distinct functions, you need a way to pass data generated in one action to another action executed later in the script. The <code>node.namespace</code> attribute serves this purpose. It is a dictionary attached to the <code>node</code> object where you can store and retrieve variables.</p> <p>You can directly assign values to keys in <code>node.namespace</code>:</p> <pre><code># Inside an action function:\nintermediate_result = 42\nnode.namespace[\"my_result\"] = intermediate_result\n</code></pre> <p>In a subsequent action, you can access this stored value:</p> <pre><code># Inside a later action function:\nprevious_result = node.namespace[\"my_result\"]\nprint(f\"The previous result was: {previous_result}\")\n</code></pre> <p>As a convenience, if an action function returns a dictionary, the contents of that dictionary are automatically added to <code>node.namespace</code>. Keys from the returned dictionary will overwrite existing keys in the namespace if they collide.</p> <p>Example: Using <code>node.namespace</code></p> <pre><code># In your QualibrationNode script...\n\n# %% {Generate_Data}\n@node.run_action\ndef generate_data(node: QualibrationNode):\n    \"\"\"Generates some data and stores it.\"\"\"\n    print(\"Generating data...\")\n    raw_data = [1, 2, 3, 4, 5]\n    # Store directly in namespace\n    node.namespace[\"raw_data\"] = raw_data\n    print(\"Raw data stored in namespace.\")\n    # Return a dict to add more items to namespace\n    # The following is equivalent to: node.namespace[\"processing_factor\"] = 10\n    return {\"processing_factor\": 10}\n\n# %% {Process_Data}\n@node.run_action\ndef process_data(node: QualibrationNode):\n    \"\"\"Processes data retrieved from the namespace.\"\"\"\n    print(\"Processing data...\")\n    # Retrieve data stored directly\n    retrieved_raw_data = node.namespace[\"raw_data\"]\n    # Retrieve data added via return dict\n    factor = node.namespace[\"processing_factor\"]\n    processed_data = [x * factor for x in retrieved_raw_data]\n    node.namespace[\"processed_data\"] = processed_data\n    print(f\"Processed data: {processed_data}\")\n\n# %% {Use_Processed_Data}\n@node.run_action\ndef use_processed_data(node: QualibrationNode):\n    \"\"\"Uses the final processed data.\"\"\"\n    final_data = node.namespace[\"processed_data\"]\n    print(f\"Using final data: {final_data}\")\n    # ... further steps ...\n</code></pre> <p>This mechanism allows for a clear flow of data between the modular steps defined by your node actions.</p>"},{"location":"node_actions/#controlling-execution-flow-with-skip_if","title":"Controlling Execution Flow with <code>skip_if</code>","text":"<p>Node Actions allow for conditional execution using keyword arguments in the decorator. The primary implemented control mechanism is the <code>skip_if</code> argument.</p> <p>If the expression passed to <code>skip_if</code> evaluates to <code>True</code>, the action will be skipped during execution. This avoids complex <code>if/else</code> blocks cluttering the main script body.</p> <p>Example: Skipping Simulation or Execution</p> <p>In a typical calibration node, you might want different execution paths: simulate a process, execute it on hardware, or load previously saved data. Node Actions with <code>skip_if</code> can manage this cleanly:</p> <pre><code># In your QualibrationNode script...\n\n# %% {Simulate_Process}\n@node.run_action(\n    skip_if=node.parameters.load_data_id is not None\n            or not node.parameters.simulate\n)\ndef simulate_process(node: QualibrationNode):\n    \"\"\"Simulate the calibration process\"\"\"\n    print(\"Simulating process...\")\n    # ... simulation logic ...\n    # Example: Store simulation results\n    # node.results[\"simulation\"] = {\"figure\": fig, ...}\n    print(\"Simulation complete.\")\n\n# %% {Execute_Process}\n@node.run_action(\n    skip_if=node.parameters.load_data_id is not None\n            or node.parameters.simulate\n)\ndef execute_process(node: QualibrationNode):\n    \"\"\"Execute the process and fetch the raw data.\"\"\"\n    print(\"Executing process...\")\n    # ... execution logic ...\n    # Example: Store raw data\n    # node.results[\"ds_raw\"] = dataset\n    print(\"Execution complete.\")\n\n# %% {Load_Data}\n@node.run_action(skip_if=node.parameters.load_data_id is None)\ndef load_data(node: QualibrationNode):\n    \"\"\"Load a previously acquired dataset.\"\"\"\n    load_data_id = node.parameters.load_data_id # Store before node is overwritten\n    print(f\"Loading data from ID: {load_data_id}...\")\n    # Load the specified dataset - Note: this populates the node variable\n    node.load_from_id(load_data_id)\n    # Restore the parameter if needed, as load_from_id might reset it\n    node.parameters.load_data_id = load_data_id\n    print(\"Data loaded.\")\n\n# %% {Analyse_Data}\n@node.run_action(skip_if=node.parameters.simulate)\ndef analyse_data(node: QualibrationNode):\n    \"\"\"Analyse the raw or loaded data.\"\"\"\n    print(\"Analysing data...\")\n    # ... analysis logic ...\n    print(\"Analysis complete.\")\n\n# %% {Save_Results}\n@node.run_action()\ndef save_results(node: QualibrationNode):\n    \"\"\"Saves the node's results.\"\"\"\n    print(\"Saving results...\")\n    node.save()\n    print(\"Results saved.\")\n</code></pre> <p>Using <code># %% {Cell Name}</code> comments before each action allows editors like VS Code to recognize these sections as runnable cells. This simplifies debugging and interactive execution of specific actions within a compatible kernel.</p> <p>In this example:</p> <ul> <li><code>simulate_process</code> only runs if <code>load_data_id</code> is <code>None</code> AND   <code>simulate</code> is <code>True</code>.</li> <li><code>execute_process</code> only runs if <code>load_data_id</code> is <code>None</code> AND   <code>simulate</code> is <code>False</code>.</li> <li><code>load_data</code> only runs if <code>load_data_id</code> is provided.</li> <li><code>analyse_data</code> runs if <code>simulate</code> is <code>False</code> (meaning we either executed   or loaded data).</li> <li><code>save_results</code> always runs at the end.</li> </ul>"},{"location":"node_actions/#benefits-of-using-node-actions","title":"Benefits of Using Node Actions","text":"<p>Using Node Actions significantly improves the clarity and maintainability of calibration scripts. Encapsulating logic in named functions makes scripts easier to read and modify, while the decorator handles conditional execution cleanly, avoiding complex <code>if</code> statements.</p> <p>Furthermore, actions function as largely independent units. Explicitly sharing data between them using <code>node.namespace</code> reduces implicit coupling compared to scripts relying on shared local variables. This modularity and reduced coupling lead to cleaner code and provide essential hooks for future enhancements, such as interactively re-running steps or building custom workflows, leading to more robust calibration nodes within the QUAlibrate framework.</p>"},{"location":"projects/","title":"Projects","text":"<p>Switching chips between fridges, splitting lab time between researchers, or running multiple calibration efforts on the same hardware all require different data paths and calibration context. Projects capture those differences so you can jump between setups without touching raw configuration files.</p> <p>Typical project changes include:</p> <ul> <li>which storage location run data is stored in</li> <li>which QUAM state the system should load</li> <li>which calibration library folder to use</li> </ul> <p>Qualibrate Projects package these overrides into named profiles that you can select in seconds\u2014either from the web app or via the CLI. You can extend a project with additional configuration keys, but these three are the ones most teams swap when moving between experiments.</p>"},{"location":"projects/#choose-a-project-in-the-web-app","title":"Choose a Project in the Web App","text":"<p>The Projects page is the quickest way to review existing projects, switch the active one, or create a new profile. Selecting a project immediately updates the active context for the entire app.</p> <p></p> <p>Creating a project in the web interface prompts you for the storage location, calibration library folder, and QUAM state path. Leave any field blank to keep the value inherited from the global configuration. Once saved, the project appears in the list so you can switch back to it whenever needed.</p>"},{"location":"projects/#manage-projects-from-the-cli","title":"Manage Projects from the CLI","text":"<p>For scripted workflows or remote access, the <code>qualibrate project</code> command group mirrors everything you can do in the web app. Add <code>--config-path</code> if you keep your configs somewhere other than <code>~/.qualibrate/config.toml</code>.</p>"},{"location":"projects/#create-a-project","title":"Create a project","text":"<pre><code>qualibrate project create &lt;name&gt; [--storage-location PATH] [--calibration-library-folder PATH] [--quam-state-path PATH]\n</code></pre> <p>Writes a minimal <code>config.toml</code> for the project containing only the overrides you provide.</p>"},{"location":"projects/#list-projects","title":"List projects","text":"<pre><code>qualibrate project list [--verbose]\n</code></pre> <p>Shows every project in <code>~/.qualibrate/projects</code>; verbose mode adds metadata such as creation timestamps, last modification, and stored overrides.</p>"},{"location":"projects/#show-the-active-project","title":"Show the active project","text":"<pre><code>qualibrate project current\n</code></pre> <p>Reveals which project QUAlibrate will use for the next runs.</p>"},{"location":"projects/#switch-projects","title":"Switch projects","text":"<pre><code>qualibrate project switch &lt;name&gt;\n</code></pre> <p>Immediately updates the global configuration so both the CLI and web app operate under the selected project.</p>"},{"location":"projects/#delete-a-project","title":"Delete a project","text":"<pre><code>qualibrate project delete &lt;name&gt;\n</code></pre> <p>Removes the project directory, blocking deletion if that project is currently active.</p> <p>Advanced overrides</p> <p>Only the three common paths are exposed as CLI flags or web form fields today. You can open a project\u2019s <code>config.toml</code> and add any other configuration entries manually whenever you need custom behaviour.</p>"},{"location":"projects/#how-projects-work","title":"How Projects Work","text":"<p>Projects extend the main configuration file located at <code>~/.qualibrate/config.toml</code>.</p> <ul> <li>The active project name lives in the <code>qualibrate.project</code> entry of the global config.</li> <li>Each project stores only its overrides under <code>~/.qualibrate/projects/&lt;name&gt;/config.toml</code>.</li> <li>At runtime, QUAlibrate merges the two files so that missing project values fall back to the global configuration.</li> </ul> <pre><code>~/.qualibrate/\n\u251c\u2500\u2500 config.toml                 # global defaults + active project name\n\u2514\u2500\u2500 projects/\n    \u2514\u2500\u2500 &lt;project&gt;/config.toml   # optional overrides\n</code></pre> <p>When a project does not override a setting, QUAlibrate simply uses the value from the global configuration, making projects an optional layer rather than a requirement.</p>"},{"location":"release_notes/","title":"Release Notes","text":""},{"location":"release_notes/#introduction","title":"Introduction","text":"<p>QUAlibrate is updated regularly to provide new features, performance improvements and bug fixes. These release notes provide more information about those changes.</p>"},{"location":"release_notes/#january-1-2026","title":"January 1, 2026","text":""},{"location":"release_notes/#v06","title":"v0.6","text":"<ul> <li>Qubit selection: Users can now easily select target qubits, with an overview of their state and fidelity.</li> <li>Static typing for parameters: Parameters are now type-validated, supporting integers, floats, lists and enumerations.</li> <li>Graphs additions: Enabled conditional operations, sub-graph visualization, and conditional on-failure logic.</li> </ul>"},{"location":"release_notes/#december-2-2025","title":"December 2, 2025","text":""},{"location":"release_notes/#v05","title":"v0.5","text":"<ul> <li> <p>Nested calibration graphs: Introduced support for composing modular calibration workflows by using existing graphs as reusable building blocks.</p> </li> <li> <p>Looping constructs: Added the ability to define loops over calibration nodes, including nested calibration graphs, with support for conditional logic.</p> </li> <li> <p>Language improvements: Simplified graph composition by enabling the use of context managers.</p> </li> </ul>"},{"location":"web_app/","title":"Web App","text":"<p>QUAlibrate comes with a dedicated web app, enabling you to run any <code>QualibrationNode</code> and <code>QualibrationGraph</code> through an intuitive frontend. The web app can be started by running the following command in the terminal:</p> <p><pre><code>qualibrate start\n</code></pre> A message should appear in the terminal specifying the URL to access the Web App, the default being http://localhost:8001/.</p>"},{"location":"web_app/#node-execution-page","title":"Node Execution Page","text":"<p>When accessing the URL on a web browser, you should be greeted by the <code>Node Execution</code> page:</p> <p></p> <p>This webpage contains a list of all nodes registered in the  <code>qualibrate_runner.calibration_library_folder</code> path in the configuration file. If you don't see any nodes in here, it may be because no nodes have yet been added to this folder.</p> <p>When selecting a node, the <code>NodeParameters</code> defined in the <code>QualibrationNode</code> file are displayed along with their default values. These default values can be overwritten, and the node can then be executed by pressing the <code>Run</code> button.</p> <p>After the node execution has finished, the results are shown on the right-hand side.  Additionally, <code>State updates</code> may be shown if QUAM entries have been updated using <code>with node.record_state_updates():</code> (see calibration nodes for details).</p>"},{"location":"web_app/#graph-library-page","title":"Graph library Page","text":"<p>The Web App also supports running calibration graphs through the <code>Graph Library</code> page. Any <code>QualibrationGraph</code> stored in the calibration library folder is displayed here and can be run with custom parameters. For example, the user can specify the targets (qubits) that the node should be applied to. Additionally, node-specific parameters can also be modified. The graph can be run by pressing the blue <code>play</code> triangle.</p> <p></p>"},{"location":"web_app/#graph-status-page","title":"Graph Status Page","text":"<p>Once a job to run a graph has been dispatched, you will be redirected to the <code>Graph Status</code> page. Here you can see the progress of the graph execution, including the results of executed nodes.</p> <p></p>"},{"location":"web_app/#data-page","title":"Data Page","text":"<p>The <code>Data</code> page shows the results of all nodes that have been executed. This includes the node results, but also the QUAM state, and any updates to QUAM that occured while executing this node.</p> <p></p>"}]}